{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "KoBert_310_dataX",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyN55YVvPAiX8as/1JY1e4fl",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suu3/Capstone/blob/main/KoBert_310_dataX.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_bwTQhc-EwG",
        "outputId": "32774b50-5638-49bd-f181-e7daf76a0c31"
      },
      "source": [
        "!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master\n",
            "  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to /tmp/pip-req-build-tqmtwt2s\n",
            "  Running command git clone -q 'https://****@github.com/SKTBrain/KoBERT.git' /tmp/pip-req-build-tqmtwt2s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qD2qEE_4-KW8",
        "outputId": "d56317b6-db3a-4392-da58-56742781c08e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUiP_jiK2C2_",
        "outputId": "322d8fe9-7d10-43cb-cbe3-560fc90b0c8a"
      },
      "source": [
        "!pip install -r /content/drive/'My Drive'/'Colab Notebooks'/buddy/requirements.txt"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kobert-transformers==0.4.1 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/My Drive/Colab Notebooks/buddy/requirements.txt (line 1)) (0.4.1)\n",
            "Requirement already satisfied: kogpt2-transformers==0.3.0 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/My Drive/Colab Notebooks/buddy/requirements.txt (line 2)) (0.3.0)\n",
            "Requirement already satisfied: transformers==3.0.2 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/My Drive/Colab Notebooks/buddy/requirements.txt (line 3)) (3.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/My Drive/Colab Notebooks/buddy/requirements.txt (line 4)) (1.9.0+cu102)\n",
            "Requirement already satisfied: tokenizers==0.8.1rc1 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/My Drive/Colab Notebooks/buddy/requirements.txt (line 5)) (0.8.1rc1)\n",
            "Requirement already satisfied: kss in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/My Drive/Colab Notebooks/buddy/requirements.txt (line 6)) (2.5.1)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/My Drive/Colab Notebooks/buddy/requirements.txt (line 7)) (1.1.4)\n",
            "Requirement already satisfied: flask_restful in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/My Drive/Colab Notebooks/buddy/requirements.txt (line 8)) (0.3.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2->-r /content/drive/My Drive/Colab Notebooks/buddy/requirements.txt (line 3)) (1.19.5)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2->-r /content/drive/My Drive/Colab Notebooks/buddy/requirements.txt (line 3)) (0.1.96)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2->-r /content/drive/My Drive/Colab Notebooks/buddy/requirements.txt (line 3)) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2->-r /content/drive/My Drive/Colab Notebooks/buddy/requirements.txt (line 3)) (21.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2->-r /content/drive/My Drive/Colab Notebooks/buddy/requirements.txt (line 3)) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2->-r /content/drive/My Drive/Colab Notebooks/buddy/requirements.txt (line 3)) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2->-r /content/drive/My Drive/Colab Notebooks/buddy/requirements.txt (line 3)) (4.41.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2->-r /content/drive/My Drive/Colab Notebooks/buddy/requirements.txt (line 3)) (0.0.45)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->-r /content/drive/My Drive/Colab Notebooks/buddy/requirements.txt (line 4)) (3.7.4.3)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask->-r /content/drive/My Drive/Colab Notebooks/buddy/requirements.txt (line 7)) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask->-r /content/drive/My Drive/Colab Notebooks/buddy/requirements.txt (line 7)) (1.1.0)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask->-r /content/drive/My Drive/Colab Notebooks/buddy/requirements.txt (line 7)) (7.1.2)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask->-r /content/drive/My Drive/Colab Notebooks/buddy/requirements.txt (line 7)) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->flask->-r /content/drive/My Drive/Colab Notebooks/buddy/requirements.txt (line 7)) (2.0.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from flask_restful->-r /content/drive/My Drive/Colab Notebooks/buddy/requirements.txt (line 8)) (2018.9)\n",
            "Requirement already satisfied: six>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from flask_restful->-r /content/drive/My Drive/Colab Notebooks/buddy/requirements.txt (line 8)) (1.15.0)\n",
            "Requirement already satisfied: aniso8601>=0.82 in /usr/local/lib/python3.7/dist-packages (from flask_restful->-r /content/drive/My Drive/Colab Notebooks/buddy/requirements.txt (line 8)) (9.0.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.0.2->-r /content/drive/My Drive/Colab Notebooks/buddy/requirements.txt (line 3)) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2->-r /content/drive/My Drive/Colab Notebooks/buddy/requirements.txt (line 3)) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2->-r /content/drive/My Drive/Colab Notebooks/buddy/requirements.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2->-r /content/drive/My Drive/Colab Notebooks/buddy/requirements.txt (line 3)) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2->-r /content/drive/My Drive/Colab Notebooks/buddy/requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2->-r /content/drive/My Drive/Colab Notebooks/buddy/requirements.txt (line 3)) (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9ONaA7l2Hmh"
      },
      "source": [
        "import sys\n",
        "sys.path.append('drive/My Drive/Colab Notebooks/')\n",
        "sys.path.append('drive/My Drive/Colab Notebooks/buddy')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4X8hDOC2JOy"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "from transformers import AdamW\n",
        "from torch.utils.data import dataloader\n",
        "from buddy.dataloader.wellness import WellnessTextClassificationDataset\n",
        "from buddy.model.kobert import KoBERTforSequenceClassfication"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOvLUSCQ2KxO",
        "outputId": "64fcd9bc-e5e9-4a0a-d2e0-fc3aca9118f0"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1P6OOtM2LfD"
      },
      "source": [
        "def train(device, epoch, model, optimizer, train_loader, save_step, save_ckpt_path, train_step = 0):\n",
        "    losses = []\n",
        "    train_start_index = train_step+1 if train_step != 0 else 0\n",
        "    total_train_step = len(train_loader)\n",
        "    model.train()\n",
        "\n",
        "    with tqdm(total= total_train_step, desc=f\"Train({epoch})\") as pbar:\n",
        "        pbar.update(train_step)\n",
        "        for i, data in enumerate(train_loader, train_start_index):\n",
        "          \n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(**data)\n",
        "\n",
        "            loss = outputs[0]\n",
        "\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            pbar.update(1)\n",
        "            pbar.set_postfix_str(f\"Loss: {loss.item():.3f} ({np.mean(losses):.3f})\")\n",
        "\n",
        "            if i >= total_train_step or i % save_step == 0:\n",
        "                torch.save({\n",
        "                    'epoch': epoch,  # 현재 학습 epoch\n",
        "                    'model_state_dict': model.state_dict(),  # 모델 저장\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),  # 옵티마이저 저장\n",
        "                    'loss': loss.item(),  # Loss 저장\n",
        "                    'train_step': i,  # 현재 진행한 학습\n",
        "                    'total_train_step': len(train_loader)  # 현재 epoch에 학습 할 총 train step\n",
        "                }, save_ckpt_path)\n",
        "\n",
        "    return np.mean(losses)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meIpH3HW2NOO"
      },
      "source": [
        "import torch, gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdLIHijo2N38",
        "outputId": "e270bcee-d9da-43a1-c1d0-ea23886a9d65"
      },
      "source": [
        "root_path = \"/content/drive/MyDrive/Colab Notebooks/buddy\"\n",
        "data_path = f\"{root_path}/data2/wellness_dialog_for_text_classification_train.txt\"\n",
        "checkpoint_path =f\"{root_path}/checkpoint\"\n",
        "save_ckpt_path = f\"{checkpoint_path}/kobert-wellness-text-classification-dataX-309.pth\"\n",
        "\n",
        "n_epoch = 50 #Num of Epoch\n",
        "batch_size = 4 #배치 사이즈 #Colab이 돌아가지 않아 4로 했으며, 증가시켜도 무방\n",
        "ctx = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device = torch.device(ctx)\n",
        "save_step = 100 #학습 저장 주기\n",
        "learning_rate = 5e-6  #Learning Rate\n",
        "\n",
        "#WellnessTextClassificationDataset Data Loader\n",
        "dataset = WellnessTextClassificationDataset(file_path=data_path, device=device)\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "model = KoBERTforSequenceClassfication()\n",
        "model.to(device)\n",
        "\n",
        "#Prepare optimizer and schedule (linear warmup and decay)\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "      'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
        "\n",
        "pre_epoch, pre_loss, train_step = 0, 0, 0\n",
        "if os.path.isfile(save_ckpt_path):\n",
        "    checkpoint = torch.load(save_ckpt_path, map_location=device)\n",
        "    pre_epoch = checkpoint['epoch']\n",
        "    train_step =  checkpoint['train_step']\n",
        "    total_train_step =  checkpoint['total_train_step']\n",
        "\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "    print(f\"load pretrain from: {save_ckpt_path}, epoch={pre_epoch}\")\n",
        "\n",
        "losses = []\n",
        "offset = pre_epoch\n",
        "for step in range(n_epoch):\n",
        "    epoch = step + offset\n",
        "    loss = train(device, epoch, model, optimizer, train_loader, save_step, save_ckpt_path, train_step)\n",
        "    losses.append(loss)\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train(0): 100%|██████████| 1189/1189 [05:34<00:00,  3.56it/s, Loss: 5.479 (5.505)]\n",
            "Train(1): 100%|██████████| 1189/1189 [05:33<00:00,  3.56it/s, Loss: 4.812 (5.355)]\n",
            "Train(2): 100%|██████████| 1189/1189 [05:41<00:00,  3.48it/s, Loss: 5.029 (5.261)]\n",
            "Train(3): 100%|██████████| 1189/1189 [05:31<00:00,  3.58it/s, Loss: 5.369 (5.070)]\n",
            "Train(4): 100%|██████████| 1189/1189 [05:37<00:00,  3.52it/s, Loss: 5.368 (4.786)]\n",
            "Train(5): 100%|██████████| 1189/1189 [05:39<00:00,  3.50it/s, Loss: 4.720 (4.491)]\n",
            "Train(6): 100%|██████████| 1189/1189 [05:39<00:00,  3.50it/s, Loss: 5.414 (4.227)]\n",
            "Train(7): 100%|██████████| 1189/1189 [05:38<00:00,  3.51it/s, Loss: 5.285 (3.968)]\n",
            "Train(8): 100%|██████████| 1189/1189 [05:35<00:00,  3.54it/s, Loss: 5.221 (3.741)]\n",
            "Train(9): 100%|██████████| 1189/1189 [05:45<00:00,  3.44it/s, Loss: 3.188 (3.499)]\n",
            "Train(10): 100%|██████████| 1189/1189 [05:37<00:00,  3.52it/s, Loss: 2.904 (3.291)]\n",
            "Train(11): 100%|██████████| 1189/1189 [05:42<00:00,  3.47it/s, Loss: 3.097 (3.079)]\n",
            "Train(12): 100%|██████████| 1189/1189 [05:39<00:00,  3.50it/s, Loss: 2.065 (2.873)]\n",
            "Train(13): 100%|██████████| 1189/1189 [05:38<00:00,  3.51it/s, Loss: 2.731 (2.690)]\n",
            "Train(14): 100%|██████████| 1189/1189 [05:36<00:00,  3.53it/s, Loss: 0.917 (2.507)]\n",
            "Train(15): 100%|██████████| 1189/1189 [05:35<00:00,  3.54it/s, Loss: 3.789 (2.331)]\n",
            "Train(16): 100%|██████████| 1189/1189 [05:47<00:00,  3.42it/s, Loss: 2.943 (2.148)]\n",
            "Train(17): 100%|██████████| 1189/1189 [05:37<00:00,  3.52it/s, Loss: 2.967 (1.990)]\n",
            "Train(18): 100%|██████████| 1189/1189 [05:45<00:00,  3.44it/s, Loss: 1.810 (1.822)]\n",
            "Train(19): 100%|██████████| 1189/1189 [05:33<00:00,  3.56it/s, Loss: 3.081 (1.671)]\n",
            "Train(20): 100%|██████████| 1189/1189 [05:58<00:00,  3.31it/s, Loss: 1.001 (1.521)]\n",
            "Train(21): 100%|██████████| 1189/1189 [05:34<00:00,  3.56it/s, Loss: 2.806 (1.385)]\n",
            "Train(22): 100%|██████████| 1189/1189 [05:39<00:00,  3.50it/s, Loss: 0.458 (1.265)]\n",
            "Train(23): 100%|██████████| 1189/1189 [05:46<00:00,  3.43it/s, Loss: 1.270 (1.130)]\n",
            "Train(24): 100%|██████████| 1189/1189 [05:37<00:00,  3.52it/s, Loss: 0.561 (1.006)]\n",
            "Train(25): 100%|██████████| 1189/1189 [05:36<00:00,  3.53it/s, Loss: 1.802 (0.901)]\n",
            "Train(26): 100%|██████████| 1189/1189 [05:39<00:00,  3.51it/s, Loss: 0.259 (0.794)]\n",
            "Train(27): 100%|██████████| 1189/1189 [05:49<00:00,  3.41it/s, Loss: 0.613 (0.704)]\n",
            "Train(28): 100%|██████████| 1189/1189 [05:38<00:00,  3.51it/s, Loss: 0.252 (0.620)]\n",
            "Train(29): 100%|██████████| 1189/1189 [05:40<00:00,  3.49it/s, Loss: 1.254 (0.535)]\n",
            "Train(30): 100%|██████████| 1189/1189 [05:43<00:00,  3.46it/s, Loss: 0.840 (0.463)]\n",
            "Train(31): 100%|██████████| 1189/1189 [05:56<00:00,  3.33it/s, Loss: 0.349 (0.398)]\n",
            "Train(32): 100%|██████████| 1189/1189 [05:33<00:00,  3.57it/s, Loss: 0.218 (0.340)]\n",
            "Train(33): 100%|██████████| 1189/1189 [05:55<00:00,  3.34it/s, Loss: 0.091 (0.288)]\n",
            "Train(34): 100%|██████████| 1189/1189 [05:34<00:00,  3.56it/s, Loss: 0.063 (0.242)]\n",
            "Train(35): 100%|██████████| 1189/1189 [05:39<00:00,  3.51it/s, Loss: 0.306 (0.209)]\n",
            "Train(36): 100%|██████████| 1189/1189 [05:45<00:00,  3.44it/s, Loss: 0.415 (0.169)]\n",
            "Train(37): 100%|██████████| 1189/1189 [05:35<00:00,  3.55it/s, Loss: 0.034 (0.140)]\n",
            "Train(38): 100%|██████████| 1189/1189 [05:36<00:00,  3.53it/s, Loss: 0.145 (0.118)]\n",
            "Train(39): 100%|██████████| 1189/1189 [05:50<00:00,  3.39it/s, Loss: 0.055 (0.093)]\n",
            "Train(40): 100%|██████████| 1189/1189 [05:29<00:00,  3.61it/s, Loss: 0.020 (0.080)]\n",
            "Train(41): 100%|██████████| 1189/1189 [05:49<00:00,  3.40it/s, Loss: 0.115 (0.082)]\n",
            "Train(42): 100%|██████████| 1189/1189 [05:33<00:00,  3.56it/s, Loss: 0.062 (0.059)]\n",
            "Train(43): 100%|██████████| 1189/1189 [05:35<00:00,  3.54it/s, Loss: 0.086 (0.042)]\n",
            "Train(44): 100%|██████████| 1189/1189 [05:44<00:00,  3.45it/s, Loss: 0.071 (0.037)]\n",
            "Train(45): 100%|██████████| 1189/1189 [05:32<00:00,  3.57it/s, Loss: 0.042 (0.053)]\n",
            "Train(46): 100%|██████████| 1189/1189 [05:35<00:00,  3.54it/s, Loss: 0.005 (0.036)]\n",
            "Train(47): 100%|██████████| 1189/1189 [05:37<00:00,  3.52it/s, Loss: 0.035 (0.022)]\n",
            "Train(48): 100%|██████████| 1189/1189 [05:36<00:00,  3.53it/s, Loss: 0.024 (0.018)]\n",
            "Train(49): 100%|██████████| 1189/1189 [05:55<00:00,  3.34it/s, Loss: 0.017 (0.019)]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zu_s1DZYF-3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b700da9e-6732-418e-8017-2d6044dc614c"
      },
      "source": [
        "\n",
        "# data\n",
        "data = {\n",
        "    \"loss\": losses\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "display(df)\n",
        "\n",
        "# graph\n",
        "plt.figure(figsize=[12, 4])\n",
        "plt.plot(losses, label=\"loss\")\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.505196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.354885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.260739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.070468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.785542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4.490721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4.226623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>3.967994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>3.740928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3.499133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>3.290909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>3.079343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2.873460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2.690167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2.506921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2.331439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2.148437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1.990114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1.822188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1.671235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1.521213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1.385500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>1.264557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>1.129604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>1.005813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.901363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.793634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.704201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.620486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.534825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.462509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.397698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.340062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.287564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.241712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0.208576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>0.169028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0.140120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>0.117865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0.092909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0.079905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>0.081796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>0.059404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>0.042042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>0.037152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>0.053335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>0.035865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>0.022045</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>0.018378</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>0.018691</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        loss\n",
              "0   5.505196\n",
              "1   5.354885\n",
              "2   5.260739\n",
              "3   5.070468\n",
              "4   4.785542\n",
              "5   4.490721\n",
              "6   4.226623\n",
              "7   3.967994\n",
              "8   3.740928\n",
              "9   3.499133\n",
              "10  3.290909\n",
              "11  3.079343\n",
              "12  2.873460\n",
              "13  2.690167\n",
              "14  2.506921\n",
              "15  2.331439\n",
              "16  2.148437\n",
              "17  1.990114\n",
              "18  1.822188\n",
              "19  1.671235\n",
              "20  1.521213\n",
              "21  1.385500\n",
              "22  1.264557\n",
              "23  1.129604\n",
              "24  1.005813\n",
              "25  0.901363\n",
              "26  0.793634\n",
              "27  0.704201\n",
              "28  0.620486\n",
              "29  0.534825\n",
              "30  0.462509\n",
              "31  0.397698\n",
              "32  0.340062\n",
              "33  0.287564\n",
              "34  0.241712\n",
              "35  0.208576\n",
              "36  0.169028\n",
              "37  0.140120\n",
              "38  0.117865\n",
              "39  0.092909\n",
              "40  0.079905\n",
              "41  0.081796\n",
              "42  0.059404\n",
              "43  0.042042\n",
              "44  0.037152\n",
              "45  0.053335\n",
              "46  0.035865\n",
              "47  0.022045\n",
              "48  0.018378\n",
              "49  0.018691"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xKaN3xkMUIV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "outputId": "63cf48da-8347-4bc0-c5f8-5f1ccb5ab2b0"
      },
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import random\n",
        "\n",
        "from model.kobert import KoBERTforSequenceClassfication, kobert_input\n",
        "from kobert_transformers import get_tokenizer\n",
        "\n",
        "def load_wellness_answer():\n",
        "  root_path = \"/content/drive/MyDrive/Colab Notebooks/buddy\"\n",
        "  category_path = f\"{root_path}/data2/wellness_dialog_category.txt\"\n",
        "  answer_path = f\"{root_path}/data2/wellness_dialog_answer.txt\"\n",
        "\n",
        "  c_f = open(category_path,'r')\n",
        "  a_f = open(answer_path,'r')\n",
        "\n",
        "  category_lines = c_f.readlines()\n",
        "  answer_lines = a_f.readlines()\n",
        "\n",
        "  category = {}\n",
        "  answer = {}\n",
        "  for line_num, line_data in enumerate(category_lines):\n",
        "    data = line_data.split('    ')\n",
        "    category[data[1][:-1]]=data[0]\n",
        "  \n",
        "  for line_num, line_data in enumerate(answer_lines):\n",
        "    data = line_data.split('    ')\n",
        "    keys = answer.keys()\n",
        "    if(data[0] in keys):\n",
        "      answer[data[0]] += [data[1][:-1]]\n",
        "    else:\n",
        "      answer[data[0]] = [data[1][:-1]]\n",
        "\n",
        "  return category, answer\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  root_path = \"/content/drive/MyDrive/Colab Notebooks/buddy\"\n",
        "  checkpoint_path =f\"{root_path}/checkpoint\"\n",
        "  save_ckpt_path = f\"{checkpoint_path}/kobert-wellness-text-classification-dataX-309.pth\"\n",
        "\n",
        "  #답변과 카테고리 불러오기\n",
        "  category, answer = load_wellness_answer()\n",
        "\n",
        "  ctx = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "  device = torch.device(ctx)\n",
        "\n",
        "  # 저장한 Checkpoint 불러오기\n",
        "  checkpoint = torch.load(save_ckpt_path, map_location=device)\n",
        "\n",
        "  model = KoBERTforSequenceClassfication()\n",
        "  model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "  model.to(ctx)\n",
        "  model.eval()\n",
        "\n",
        "  tokenizer = get_tokenizer()\n",
        "\n",
        "  while 1:\n",
        "    sent = input('\\nQuestion: ') # '요즘 기분이 우울한 느낌이에요'\n",
        "    data = kobert_input(tokenizer, sent, device, 512)\n",
        "\n",
        "    if '종료' in sent:\n",
        "      break\n",
        "\n",
        "    output = model(**data)\n",
        "\n",
        "    logit = output[0]\n",
        "    softmax_logit = torch.softmax(logit,dim=-1)\n",
        "    softmax_logit = softmax_logit.squeeze()\n",
        "\n",
        "    max_index = torch.argmax(softmax_logit).item()\n",
        "    max_index_value = softmax_logit[torch.argmax(softmax_logit)].item()\n",
        "\n",
        "    answer_list = answer[category[str(max_index)]]\n",
        "    answer_len= len(answer_list)-1\n",
        "    answer_index = random.randint(0,answer_len)\n",
        "    print(f'Answer: {answer_list[answer_index]}, index: {max_index}, softmax_value: {max_index_value}')\n",
        "    print('-'*50)\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    582\u001b[0m         \"\"\"\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-bba6a0d4dc83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nQuestion: '\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# '요즘 기분이 우울한 느낌이에요'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkobert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vW0_62qtJD3q"
      },
      "source": [
        "평가함수\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6l63ZOTJDs5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ddb818b-0e9a-4129-b892-b7aea34c92e6"
      },
      "source": [
        "import os\n",
        "import logging\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "from transformers import (\n",
        "  AdamW,\n",
        "  ElectraConfig,\n",
        "  ElectraTokenizer\n",
        ")\n",
        "from torch.utils.data import dataloader\n",
        "from dataloader.wellness import WellnessTextClassificationDataset\n",
        "#from model.koelectra import koElectraForSequenceClassification\n",
        "from model.kobert import KoBERTforSequenceClassfication\n",
        "from kobert_transformers import get_tokenizer\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "MODEL_CLASSES ={\n",
        "  #\"koelectra\": (ElectraConfig, koElectraForSequenceClassification, ElectraTokenizer),\n",
        "  \"kobert\": (KoBERTforSequenceClassfication)\n",
        "}\n",
        "CHECK_POINT ={\n",
        "  #\"koelectra\": \"/content/drive/MyDrive/Colab Notebooks/buddy/checkpoint/koelectra-wellnesee-text-classification.pth\",\n",
        "  \"kobert\": \"/content/drive/MyDrive/Colab Notebooks/buddy/checkpoint/kobert-wellness-text-classification-dataX-309.pth\"\n",
        "}\n",
        "\n",
        "def get_model_and_tokenizer(model_name, device):\n",
        "  save_ckpt_path = CHECK_POINT[model_name]\n",
        "\n",
        "#  if model_name== \"koelectra\":\n",
        "#    model_name_or_path = \"monologg/koelectra-base-discriminator\"\n",
        "\n",
        "#    tokenizer = ElectraTokenizer.from_pretrained(model_name_or_path)\n",
        "#    electra_config = ElectraConfig.from_pretrained(model_name_or_path)\n",
        "#    model = koElectraForSequenceClassification.from_pretrained(pretrained_model_name_or_path=model_name_or_path,\n",
        "#                                                               config=electra_config,\n",
        "#                                                               num_labels=359)\n",
        "  if model_name =='kobert':\n",
        "    tokenizer = get_tokenizer()\n",
        "    model = KoBERTforSequenceClassfication()\n",
        "\n",
        "  if os.path.isfile(save_ckpt_path):\n",
        "      checkpoint = torch.load(save_ckpt_path, map_location=device)\n",
        "      pre_epoch = checkpoint['epoch']\n",
        "      # pre_loss = checkpoint['loss']\n",
        "      model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "      print(f\"load pretrain from: {save_ckpt_path}, epoch={pre_epoch}\")\n",
        "\n",
        "  return model, tokenizer\n",
        "\n",
        "def get_model_input(data):\n",
        "  if model_name =='kobert':\n",
        "    return data\n",
        "#  elif model_name== \"koelectra\":\n",
        "#    return {'input_ids': data['input_ids'],\n",
        "#              'attention_mask': data['attention_mask'],\n",
        "#              'labels': data['labels']\n",
        "#              }\n",
        "\n",
        "def evaluate(model_name, device, batch_size, data_path):\n",
        "\n",
        "  model, tokenizer = get_model_and_tokenizer(model_name, device)\n",
        "  model.to(device)\n",
        "\n",
        "  # WellnessTextClassificationDataset 데이터 로더\n",
        "  eval_dataset = WellnessTextClassificationDataset(file_path=data_path,device=device, tokenizer=tokenizer)\n",
        "  eval_dataloader = torch.utils.data.DataLoader(eval_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "  logger.info(\"***** Running evaluation on %s dataset *****\")\n",
        "  logger.info(\"  Num examples = %d\", len(eval_dataset))\n",
        "  logger.info(\"  Batch size = %d\", batch_size)\n",
        "\n",
        "  loss = 0\n",
        "  acc = 0\n",
        "\n",
        "\n",
        "  # model.eval()\n",
        "  for data in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
        "    with torch.no_grad():\n",
        "      inputs = get_model_input(data)\n",
        "      outputs = model(**inputs)\n",
        "      loss += outputs[0]\n",
        "      logit = outputs[1]\n",
        "      acc += (logit.argmax(1)==inputs['labels']).sum().item()\n",
        "\n",
        "  return loss / len(eval_dataset), acc / len(eval_dataset)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  #root_path = \"/content/drive/MyDrive/Colab Notebooks/buddy/data\"\n",
        "  root_path = \"/content/drive/MyDrive/Colab Notebooks/buddy\"\n",
        "  data_path = f\"{root_path}/data/wellness_dialog_for_text_classification_test.txt\"\n",
        "  checkpoint_path = f\"{root_path}/checkpoint\"\n",
        "  save_ckpt_path = f\"{checkpoint_path}/kobert-wellness-text-classification-dataX-309.pth\"\n",
        "  #model_name_or_path = \"monologg/koelectra-base-discriminator\"\n",
        "\n",
        "  n_epoch = 50  # Num of Epoch\n",
        "  batch_size = 16  # 배치 사이즈\n",
        "  ctx = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "  device = torch.device(ctx)\n",
        "  model_names=[\"kobert\"]\n",
        "  for model_name in model_names:\n",
        "    eval_loss, eval_acc = evaluate(model_name, device, batch_size, data_path)\n",
        "    print(f'\\tLoss: {eval_loss:.4f}(valid)\\t|\\tAcc: {eval_acc * 100:.1f}%(valid)')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "load pretrain from: /content/drive/MyDrive/Colab Notebooks/buddy/checkpoint/kobert-wellness-text-classification-dataX-309.pth, epoch=49\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 33/33 [00:09<00:00,  3.52it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tLoss: 0.7704(valid)\t|\tAcc: 1.7%(valid)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73KXoMIagVS8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}